[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CCESR Intern Hub",
    "section": "",
    "text": "Welcome!\nThis website / HTML book is intended to collect resources for Cedar Creek summer interns doing independent research projects, and present those resources in an easily accessible way.\nFor now, the focus is primarily on data analysis and using the R programming language.\nMuch of the content featured is adapted from the work of past CCESR Fellows, including Mariana Cardenas and Bea Baselga.\nThis site is structured in different parts, which can be read in any order you choose, depending on your needs / what you already know. Currently, the first part goes over data analysis in general, the second part describes R-related software and workflows, and the third part is intended to give a primer in R coding."
  },
  {
    "objectID": "da_glance.html",
    "href": "da_glance.html",
    "title": "1  Data Analysis at a Glance",
    "section": "",
    "text": "Analyzing your data is usually about transforming long spreadsheets into a form that is relevant to your question/s, and oftentimes including an appropriate statistical approach for inference.\nYou might use descriptive statistics, which is simply describing what you observed without presenting every data point, and instead a summary of those data. This can often be helpful in providing a frame of reference to your dataset before looking deeper at trends and comparisons. Alternatively, sometimes descriptive statistics are the main goal - like in surveys of populations and communities (e.g., what is the population size of a certain grass of interest in an old field?). Descriptive statistics include things like the mean and variance, but can also include more niche measures like dispersion.\nYou could also use inferential statistics, which is more about using math or simulation techniques to infer some conclusion form the shape of your data. This is directly relevant to when you have an ecological question about cause and effect, associations among variables, comparisons among categories, etc. The results of inferential statistics provide a starting point from which to interpret/discuss an answer to your question. Examples include t-tests and linear regression.\nWhen using both of these types of statistics, you should be mindful of data types, which are the form that variables take. For example, the height of a tree is number, but the species of a tree is a category. This contrast is obvious, but there are subtle differences that can be important for how you describe, assess, and plot your data."
  },
  {
    "objectID": "da_data.html#numeric-data",
    "href": "da_data.html#numeric-data",
    "title": "2  Data Types",
    "section": "2.1 Numeric Data",
    "text": "2.1 Numeric Data\nAny data that can be described with numbers or have quantifiable relationships between values is numeric. But! There are multiple types of numeric data. The most important distinction is discrete vs continuous.\nDiscrete numeric data is data where not every value is possible, but you can still quantify specific differences among the possible values - the major exmaple being integer values (1, 2, 3, the rest). Most programming languages will refer to this type as integer or int. Examples might include number of ants on a log.\nContinuous numeric data is data where every valuable is possible! So this is basically all real numbers, including decimals (1.0, 1.1, etc.). Many programming languages will refer to this as simply numeric data, but lower level languages might use “float” or “double”. Examples might include th biomass of ants on a log. Note: measures that consist of very large integer values are approximately continuous.\nOther things to consider with numeric data is whether the scale of measurement is bound by any values. For example, the number of or biomass of ants on a log cannot be less than zero. In addition, percentages and proportions are bound by 0 and 100 and 0 and 1 respectively. These limitations can lead to special considerations when performing inferential statistics."
  },
  {
    "objectID": "da_data.html#categorical-data",
    "href": "da_data.html#categorical-data",
    "title": "2  Data Types",
    "section": "2.2 Categorical Data",
    "text": "2.2 Categorical Data\nAny data for which the values have no specifically quantitative difference among them is categorical. Again there is one majorly important distinction: nominal vs ordinal.\nNominal data is data where categories have no ranking or order, like the species of ants on a log.\nOrdinal data is data where categories have some order, like your top 5 favorite breakfast cereals. But wait! You may be thinking - “isn’t this quantitative?” Well yes and no. The difference between ordinal data and discrete numeric data is that you can’t really quantify the exact difference between ordinal data values. Say there is a go-kart race between Mario, Luigi, and Peach. The place that each finished would be ordinal, e.g., Peach got 1st and Luigi 2nd, but you wouldn’t be able to say how much faster Peach was than Luigi. The time it took for Peach and Luigi each to finish the race would be a numeric variable, and there would be a specific value difference between them."
  },
  {
    "objectID": "da_describe.html#centrality",
    "href": "da_describe.html#centrality",
    "title": "3  Descriptive Statistics",
    "section": "3.1 Centrality",
    "text": "3.1 Centrality\nYou’ll often want to describe the central tendency of your data - around where are the values centered?\nMean - the average of the values, or the sum of all values divided by the number of observations\nMedian - the value at which half of the observations are greater, and the other half are less\nMode - the most commonly observe value\nUsually, the mean is a a perfectly adequate descriptor. You can use it on continuous numeric data, discrete numeric data (though the mean value will often be unrealistic), or even ordinal rankings.\nWhen might you prefer to use the median over the mean?\nWhen the data is skewed such that there are many small values and a few big values, the mean might be inflated by those large values, and thus overestimate the central tendency in some contexts.\nWhen data is roughly normally distributed, the mean and median are roughly the same:\n\n\n\n\n\nBut when data are skewed, the median may be a better estimate of the central tendency:"
  },
  {
    "objectID": "da_describe.html#spread",
    "href": "da_describe.html#spread",
    "title": "3  Descriptive Statistics",
    "section": "3.2 Spread",
    "text": "3.2 Spread\nYou also might be interested in how varied your data is, how much it deviates from the central tendency. This can be done with the following:\nVariance - how variable is the data? Measured as the average squared difference between observations and the mean:\n\\[\nVariance = \\frac{\\sum (Observation_i - Mean)^2}{Number of Observations}\n\\]\n(\\(\\sum\\) means “sum of”)\nThe differences are squared to get rid of negative differences, because other wise everything would cancel out and our variance would be zero!\nStandard Deviation - the square root of the variance. This is useful because it is in the same units as the original measurements!"
  },
  {
    "objectID": "da_describe.html#other-descriptors",
    "href": "da_describe.html#other-descriptors",
    "title": "3  Descriptive Statistics",
    "section": "3.3 Other Descriptors",
    "text": "3.3 Other Descriptors\nAnother descriptor that may prove useful is the dispersion, or the variance divided by the mean. This provides an estimate of how skewed the data is - for example, the first plot above has very low dispersion, while the second plot has high dispersion."
  },
  {
    "objectID": "da_describe.html#ecological-community-descriptors",
    "href": "da_describe.html#ecological-community-descriptors",
    "title": "3  Descriptive Statistics",
    "section": "3.4 Ecological Community Descriptors",
    "text": "3.4 Ecological Community Descriptors\nMany of you are interested in describing the species composition of of community. Here’s a few common descriptors:\nSpecies Richness - this is just the number of different species present.\nSpecies Diversity - this is an index that takes into account the richness as well as the relative abundances of each species. E.g. Shannon’s Diversity Index, where higher numbers mean more species more evenly distributed.\nSpecies Evenness - this is an index that estimates specifically how evenly distributed species abundances are. E.g., Pielou’s Evenness, which ranges from 0 to 1, with 1 meaning that each species has equal numbers."
  },
  {
    "objectID": "da_infer.html#classic-frequentist-tests",
    "href": "da_infer.html#classic-frequentist-tests",
    "title": "4  Inferential Statistics",
    "section": "4.1 Classic Frequentist Tests",
    "text": "4.1 Classic Frequentist Tests\nNow let’s go over some statistical tests! For this section, it can be useful to remind ourselves of the variables involved in a research question:\nIndependent / Explanatory / Predictor Variable: this is either what you are manipulating in an experiment or what your study is designed to capture variation in (e.g., C02 at BioCON, species richness at BigBio).\nDependent / Response Variable: these are what you measure or observe throughout your study, generally hypothesizing that they will differ among the levels of your independent variable (e.g., aboveground biomass in BioCON or BigBio).\n\n4.1.1 Assumptions\nWe should mention what these tests generally assume about your data.\nFirst, they assume that your data are independent. This just means that no two observations of your data are more related to eachother in a way that isn’t accounted for by a variable. Say you were comparing mean tree height between two forests - individual tree heights in the same forest would be independent, but two measures of the same tree on different days would be non-independent.\nSecond, they assume that the errors are normally distributed. This is a bit more confusing without a statistical background. An example may be illustrative - in the tree height example above, we assume that the individual tree height are normally distributed about the mean. Without getting too much into the weeds, if you collect enough data (i.e., 30+ observations), these errors will likely be approximately normally distributed. However, things get divcey when we deal with data that is not continuous like tree height, for example, discrete count data - more on that below.\nThird, they assume homogeneity of variance. This is another complicated one, but it mean that the variance of the errors doesn’t change with the independent variable. In the tree example, we are assuming that the variance of the differences between observed tree heights and the forest mean does not change between forests.\nData that break the first assumption are difficult to deal with outside of accounting for the non-independence factor (which can severely reduce the size of your sample), but failing to meet the second or third assumptions generally leads to transforming data or using alternative tests.\n\n\n4.1.2 Categorical Predictor/s, Numeric Response\n\n4.1.2.1 Two Predictor Categories\nWhen you are comparing numeric values from two groups, you can use a t-test to compare their means. T-tests can be paired when each observation in one group is specifically linked to an observation in the other group (e.g., masses of sibling plants in separate treatments) which can be more powerful. When the variance of values in each group changes, you can do a t-test with unequal variance.\nThe effect size here is the difference between means.\n\n\n4.1.2.2 More Than Two Predictor Categories\nIf you have more than two groups/categories, you can use a Analysis of Variance or ANOVA. This will tell you if the means of each group are equivalent, or if there is at least one inequality. You can test for pairwise comparisons among the groups with Tukey’ test. If you have multiple categorical predictors, you can do two-way or three-way ANOVAs. Tests with more than three categorical predictor variables are uncommon and harder to interpret.\nThe effect sizes are the pairwise difference in means.\n\n\n4.1.2.3 Ordinal Predictors\nWhen your predictor variable is ordinal, the quick and easy way to analyze it would be to convert the predictor to a numeric integer data type and proceed from there. However this is imprecise…\nThis section is under construction\n\n\n\n4.1.3 Numeric Predictor/s, Numeric Response\n\n4.1.3.1 Simple Association\nWhen all you are interested in is whether two numeric variables are related to one another, not cause and effect, you can do a correlation test. Pearson’s correlation is generally applicable for continuous data. Spearman’s correlation is good for when you are dealing with data with non-normal distributions, like count data (it also works for ordinal data!).\nThe effect size here will be a correlation coefficient ranging from -1 to 1, with -1 means an inverse relationship, 0 means no relationship, and 1 mean a direct positive relationship.\nCause and Effect\nWhen you are suppose a causal relationship between numeric variables, you can use a linear regression. This will use linear algebra or maximum likelihod estimation (don’t worry about it) to find the best fit line that describes the relationship between two variables; where the sum of the squared distances from the observations to the line is minimized. You can also include multiple predictor variables to perform multiple linear regression AKA multivariate linear regression.\nWhen your response variable is count data, the assumptions of simple linear regression are usually unmet, so you can use generalized forms like a Poisson regression or a Negative Binomial Regression.\nThe effect sizes here are the parameter coefficients, i.e., how much does the response change for on unit increase in the predictor? Note: these are not straightforward for Poisson and negative binomial regression, so ask your mentor.\n\n\n\n4.1.4 Numeric Predictor/s, Categorical Response\n\n4.1.4.1 Binary Response\nWhen your categorical response is only two categories (e.g., presence or absence), you can use a binomial regression AKA logistic regression. This works similarly to linear regression, but the effect sizes are measured in log odds, which is difficult to interpret, but can be transformed to estimating how the probability of one category value over the other increases with a variable.\n\n\n4.1.4.2 Multiple Response Categories\nMultinomial regression (under construction)\n\n\n\n4.1.5 Categorical Predictor/s, Categorical Response\nChi-square test (under construction)"
  },
  {
    "objectID": "da_infer.html#bootstrapping",
    "href": "da_infer.html#bootstrapping",
    "title": "4  Inferential Statistics",
    "section": "4.2 Bootstrapping",
    "text": "4.2 Bootstrapping\nOne alternative to these classic tests has no assumptions: bootstrapping. Essentially, it involves using the sampled data to simulate more samples, and compare your observations to those simulations.\nEmpirical Bootstrapping is where you take your actual observations and shuffle which value is associated with which observation. For example, you could take measurements of tree heights from two forests, and randomly assign forest ID to each measurement.\nParametric Bootstrapping is where you summarize your observed data and use it to generat simulated data. For example, you could calculate the mean and variance of tree heights in two forests and then generate simulated forests of trees through random pulls from a normal distribution with the appropriate mean and variance.\nWith both approaches, you simulate a large number of simulated datasets (1000+), and then calculate whatever you are interested in for each of those simulations, and compare the calculation from the observed data to the distribution of simulated values. For example, if you empirically bootstrap the two forests of tree heights 1000 times, and then calculate difference in means for each you will have 1000 mean difference values. The proportion of those simulated values that are equal to or more extreme than your observed mean difference is your p-value!"
  },
  {
    "objectID": "rc_r.html#r-the-language",
    "href": "rc_r.html#r-the-language",
    "title": "5  R Itself",
    "section": "5.1 R, the Language",
    "text": "5.1 R, the Language\nR is a programming language designed for statistical computing, and is often the language of choice for scientists. R is also used for data science in some business, tech, and health contexts ( but many prefer Python in those areas).\nAs a programming language it is essentially an expandable collection of functions with syntax to perform tasks, and it could be written in any text editor. However, in order for your computer to interpret the language, it needs some software."
  },
  {
    "objectID": "rc_r.html#r-the-software",
    "href": "rc_r.html#r-the-software",
    "title": "5  R Itself",
    "section": "5.2 R, the Software",
    "text": "5.2 R, the Software\nThe R application allows you to run R code on your computer, and comes with a basic “console” window where code is run and output is printed, as well as a basic script editor where you can write code to run.\nYou can download the application from here:\nhttps://cran.r-project.org/\nIf you are asked to select a mirror, simply select the nearest one (I believe Iowa State should work).\nIf you have a Windows machine, it should be fairly straightforward to simply download and install the “base” R from the link.\nIf you have a Mac, you will want to select the .pkg file that matches your processor type: x-86 for Intel processors (mostly Macs pre-2020), arm64 for Macs with the M1 or M2 chip (most Macs post-2020).\nIf you are using Linux, you know more than me."
  },
  {
    "objectID": "rc_r.html#r-packages",
    "href": "rc_r.html#r-packages",
    "title": "5  R Itself",
    "section": "5.3 R Packages",
    "text": "5.3 R Packages\nAs mentioned above, R is expandable. You can add more functionality to R by installing packages. Packages contain more options of code to use to process and analyze data, and also do many other things.\nPackages can be installed through writing R code, or by clicking some buttons in RStudio. Then they will live in a directory that was built when you installed R for auxiliary packages.\nWe will discuss more about installing packages in the R coding section."
  },
  {
    "objectID": "rc_rstudio.html#rstudio-at-a-glance",
    "href": "rc_rstudio.html#rstudio-at-a-glance",
    "title": "6  R Studio",
    "section": "6.1 RStudio at a Glance",
    "text": "6.1 RStudio at a Glance\nIf you open up RStudio, you will see something like this:\n\n1- Script Editor: Here is where you will write code! You can create an R script (a text document to save code in) with the file tab, and write what you need in the resulting script. It is highly recommended to use scripts, because then you can save your code for later, and troubleshoot errors easier. From this window, you can highlight code and run it with the “Run” button on top, or with Ctrl + Enter / Cmd +Enter.\n2- R Console: Here is where the action happens - code will run here, and text output, warnings and messages will be displayed. You can also type code into the console, but that is only recommended for installing packages, entering credentials, rendering documents, and things of that nature. Don’t type your data processing or analysis code into the console, use a script instead! There’s also a terminal tab if you ever need to perform shell commands.\n3- Environment and History: Here you can find a list of the variables and data you have loaded into your “workspace” or “environment” in the Environment tab. These are objects you can do stuff with with code. You can also click the History tab to see the code you have run thus far.\n4- Files and Plots: Here is where any figures you draw will pop up (and you can save them from here as well). There is also a Files tab that allows you to navigate through your file directory (helpful with projects, described below). The Packages tab shows which packages you have installed and loaded (you can also click “Install” at top to easily install new ones!). Finally, the help tab is where you can search for the documentation on any R function."
  },
  {
    "objectID": "rc_rstudio.html#r-projects",
    "href": "rc_rstudio.html#r-projects",
    "title": "6  R Studio",
    "section": "6.2 R Projects",
    "text": "6.2 R Projects\nIt is highly recommended to use R Projects when working with RStudio. Projects are essentially just subdirectories in your file folders, but they come with a special .Rproj file that RStudio can read and use. This helps you organize your work, and makes your code more easily portable.\nYou can create a new projects from the File tab at upper left, or in the project dropdown menu at upper right.\nThere are many different types of projects - this book/website is one!\nIf you want to backup your work with version control or collaborate with others using git and GitHub, you will need to use projects. (Well, technically you don’t need to, but you’d be doing many things manually)"
  },
  {
    "objectID": "rc_git.html",
    "href": "rc_git.html",
    "title": "7  Optional: Git and Github",
    "section": "",
    "text": "If you are interested in:\n\nBacking up your code using a version control system that allows you to roll back changes and monitor incremental progress\nand/or\nSharing your code and collaborating with others\n\nYou may like to try using git (a program for your computer) and GitHub (a website that hosts code projects).\nWe won’t go into detail here, but Jenny Bryan’s excellent introduction and tutorial on the topic can be found here:\nhttps://happygitwithr.com/"
  },
  {
    "objectID": "r_basics.html#intro",
    "href": "r_basics.html#intro",
    "title": "8  The Basics",
    "section": "8.1 Intro",
    "text": "8.1 Intro\nI’m sure those of you reading this come from a wide variety of backgrounds regarding computer programming - some of you may be very familiar with it, others total novices. Some of you may love computing, others might hate it. If you’re apprehensive about learning R, or if you find yourself struggling with it - don’t worry! Scientific computing presents a challenge at some point to everyone who does it. Just remember a few things:\n\nEveryone makes mistakes.\nDon’t be afraid to ask questions!\nDon’t compare yourself to others, compare you today to you yesterday.\nEveryone is constantly learning new things, including those who seem like experts.\n\nThat said, learning a programming language is a little like learning a human language, except there’s a much smaller vocabulary and the grammar is very strict. And where human language has parts of speech like nouns and verbs, R has a certain syntax as well. Some of the main components of the R language are operators, functions, arguments, and data."
  },
  {
    "objectID": "r_basics.html#operators",
    "href": "r_basics.html#operators",
    "title": "8  The Basics",
    "section": "8.2 Operators",
    "text": "8.2 Operators\nOperators are short symbols that tell the computer to do certain simple things. You are already familiar with many operators - the math operators like +, -, *, and /. R at its simplest is a calculator:\n\n## This is block of R code! Anything that starts with # is a comment, and doesn't run.\n\n## adding\n2 + 2\n\n[1] 4\n\n## subtracting\n5 - 4\n\n[1] 1\n\n## multiplying\n3 * 3\n\n[1] 9\n\n## dividing\n6 / 2\n\n[1] 3\n\n\nThere are a couple other math operators too:\n\n## exponentiate with ^\n3^2\n\n[1] 9\n\n## find the remainder with the modulus, %%\n10 %% 3\n\n[1] 1\n\n## perform integer division with %/%\n10 %/% 3\n\n[1] 3\n\n\nBut math operators aren’t the only type! There are also the closely related comparison operators, which will return TRUE or FALSE instead of calculated numbers:\n\n## equals, ==\n2 + 2 == 4\n\n[1] TRUE\n\n## does not equal, !=\n2 + 2 != 4\n\n[1] FALSE\n\n## greater than, &gt;\n5 &gt; 4\n\n[1] TRUE\n\n## less than, &lt;\n5 &lt; 4\n\n[1] FALSE\n\n\nThere are also greater than or equal to (&gt;=) and less than or equal to (&lt;=).\nYou can combine comparisons with logical operators - and (&), or (|), and not (!):\n\n## and: are both true?\n(3 &gt; 2) & (4 &gt; 3) \n\n[1] TRUE\n\n## or: is at least one true?\n(2 == 1) | (4 &lt; 3)\n\n[1] FALSE\n\n## not: is this false?\n!(2 == 1)\n\n[1] TRUE\n\n\nThere are few other important operators, but they will make more sense once we talk about the other parts of R."
  },
  {
    "objectID": "r_basics.html#functions",
    "href": "r_basics.html#functions",
    "title": "8  The Basics",
    "section": "8.3 Functions",
    "text": "8.3 Functions\nFunctions are words (though not necessarily real words) or letters that instruct the computer to perform more complicated tasks. They generally are followed by parentheses ().\n\n## here's a function that returns the current date\nSys.Date()\n\n[1] \"2023-07-21\"\n\n## and here is a function that returns the date with the time\nSys.time()\n\n[1] \"2023-07-21 11:11:42 CDT\"\n\n\nNo you may be thinking - “this is pretty basic” and “what are the parentheses for?”, which brings use to arguments!"
  },
  {
    "objectID": "r_basics.html#arguments",
    "href": "r_basics.html#arguments",
    "title": "8  The Basics",
    "section": "8.4 Arguments",
    "text": "8.4 Arguments\nArguments are values or objects that go inside the parentheses of functions to specify what you want the function to do. This is what gives functions their power. Arguments are separated inside a function by commas.\n\n## the sum function can sum many numbers\nsum(1,2,3,4,5)\n\n[1] 15\n\n\nIn the function above, each number is acting as an argument. In this case, the arguments don’t have names. Oftentimes a function’s arguments will be explicitly named, and to specify what you want those arguments to be, you use the = operator.\n\n## this function pulls values randomly from a normal distribution specified in the arguments\n## n specifies how many numbers to return, and mean and sd specify shape of the distribution\nrnorm(n = 10, mean = 5, sd = 1)\n\n [1] 5.527450 4.770936 6.269055 4.599314 5.745492 4.624406 6.522951 6.469926\n [9] 5.022902 5.309935\n\n\nOperators are actually a special type of function that can be used with syntax that is more intuitive for them. You can also use them in the same way as most functions by surrounding them with back ticks, `.\n\n## here we use the + operator in a much more confusing context\n`+`(2, 2)\n\n[1] 4\n\n## it is equivalent to\n2 + 2\n\n[1] 4"
  },
  {
    "objectID": "r_basics.html#data",
    "href": "r_basics.html#data",
    "title": "8  The Basics",
    "section": "8.5 Data",
    "text": "8.5 Data\nWe are using the word data here to broadly encompass values (like the numbers we were using above, both with operators and as arguments), variables (stored values), and data structures (organized collections of values).\n\n8.5.1 Values\nValues are much like the data types we discuss in the data analysis section. In fact, the different types of values R can deal with are called data types as well!\nIn R, values can be numeric, character, or logical (among other, more specific types).\n\n## numeric values are numbers!\n2\n\n[1] 2\n\n2.5\n\n[1] 2.5\n\n## character values are letters, words, phrases (often referred to as \"strings)\n\"a\"\n\n[1] \"a\"\n\n\"apple\"\n\n[1] \"apple\"\n\n\"there is a worm in my apple\"\n\n[1] \"there is a worm in my apple\"\n\n## note: character values or strings must be surrounded by \"\" or '' for R to interpret them as strings\n\n## Logical values are TRUE or FALSE (you've seen these above)\nTRUE\n\n[1] TRUE\n\nFALSE\n\n[1] FALSE\n\n\nThere are other types of values too: missing values (NA and NaN), infinite values (Inf and -Inf), and something that indicates empty (NULL).\n\n\n8.5.2 Variables\nVariables are named values that are stored in the “environment”, or the workspace that R can access to perform its tasks. In order to store a value as a variable, you need to use a special kind of operator called an assignment operator (&lt;- or =). As I mentioned variables have names, which are unquoted text.\n\n## store 2 as a variable called x\nx &lt;- 2\n\n## R returns no output here because you're just storing a value\n## but you can return the value by calling the variable\nx\n\n[1] 2\n\n## store 3 as a variable called y\ny &lt;- 3\n\n## you use variables with operators\nx + y\n\n[1] 5\n\n## store a character value\nstring &lt;- \"hello\"\n\n## math doesn't work on strings\n\nTechnically, you can use = in place of &lt;-. This is why the equals operator is ==. I generally use &lt;- to prevent any confusion between assignment and comparison.\n\n8.5.2.1 Naming Rules\nVariables have rules about how they can be named:\n\nNo special symbols other than _ and .\nYou can’t start with a number or _.\nThey can’t be special words that R interprets differently. You can enter ?Reserved in your console to see a list.\n\n\n\n\n8.5.3 Data Structures\nData structures are collections of values with some sort of organization, and also saved in the environment. Plot twist: the variables above are a the simplest data structure, the scalar, which is just a single value.\nThe next data structure is the vector, which is a collection of values of the same data type. We can store them much like variables.\n\n## we use another operator, :, to create a sequence of integers from 1 to 10\nmy_vector &lt;- 1:5\n\nmy_vector\n\n[1] 1 2 3 4 5\n\n## you can also create vectors with the combine function, c()\nmy_other_vector &lt;- c(\"a\", \"b\", \"c\")\n\nmy_other_vector\n\n[1] \"a\" \"b\" \"c\"\n\n\nThe next data structure is called a list. A list is a collection of values like a vector, but they can be of any data type, or data structure. You can have a list of numeric values and character values, a list of vectors, or even a lists of lists! Every other complex data structure is technically a list with special attributes and/or rules.\n\n## you can create lists with the list function\nmy_list &lt;- list(\"a\", 1, 2:4)\n\nmy_list\n\n[[1]]\n[1] \"a\"\n\n[[2]]\n[1] 1\n\n[[3]]\n[1] 2 3 4\n\n## can also use the combine function, but it will default to a vector when data types are the same\nmy_other_list &lt;- c(\"b\", 2)\n\nFinally, the most common special type of list you will use is the data frame. A data frame is a list of vectors that are arranged in a table, much like an excel spreadsheet. Each of the vectors will be named as a column, and all must be the same length. The position of a value in a vector is its row in the data frame.\n\n## we can make a data frame with the data.frame function\nmy_data &lt;- data.frame(letter = c(\"a\",\"b\",\"c\"),\n                      number = c(1, 2, 3),\n                      vowel = c(TRUE, FALSE, FALSE))\n\nmy_data\n\n  letter number vowel\n1      a      1  TRUE\n2      b      2 FALSE\n3      c      3 FALSE\n\n\nNext, we will extend these concepts a bit further!"
  },
  {
    "objectID": "r_next.html#packages",
    "href": "r_next.html#packages",
    "title": "9  Next Steps",
    "section": "9.1 Packages",
    "text": "9.1 Packages"
  },
  {
    "objectID": "r_next.html#subsetting",
    "href": "r_next.html#subsetting",
    "title": "9  Next Steps",
    "section": "9.2 Subsetting",
    "text": "9.2 Subsetting"
  },
  {
    "objectID": "r_next.html#optional-flow-control",
    "href": "r_next.html#optional-flow-control",
    "title": "9  Next Steps",
    "section": "9.3 Optional: Flow Control",
    "text": "9.3 Optional: Flow Control"
  },
  {
    "objectID": "r_next.html#optional-writing-functions",
    "href": "r_next.html#optional-writing-functions",
    "title": "9  Next Steps",
    "section": "9.4 Optional: Writing Functions",
    "text": "9.4 Optional: Writing Functions"
  }
]